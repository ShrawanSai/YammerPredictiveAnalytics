{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "FB Scraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "GfByw5T_cz6Z"
   },
   "source": [
    "groups = ['InsaneTech','143322019583033','pypcom']"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "uyiMi5GWhB8v",
    "outputId": "0a0b0c98-cb0d-4a47-ce6f-d5e81fb47dc3"
   },
   "source": [
    "dicts = []\n",
    "for g in groups:\n",
    "    \n",
    "    d = {'post_id':[], 'text': [], 'time':[],'image':[],'video':[],'likes':[],'comments':[],'shares':[],\n",
    "            'post_url':[],'reactors':[]}\n",
    "    c=0\n",
    "    for post in get_posts(group = g):\n",
    "\n",
    "        d['post_id'].append(post['post_id'])\n",
    "        d[\"text\"].append(post['text'])\n",
    "        d[\"time\"].append(post['time'])\n",
    "        d[\"image\"].append(post['image'])\n",
    "        d[\"video\"].append(post['video'])\n",
    "        d[\"likes\"].append(post['likes'])\n",
    "        d[\"comments\"].append(post['comments'])\n",
    "        d[\"shares\"].append(post['shares'])\n",
    "        d[\"post_url\"].append(post['post_url'])\n",
    "        d[\"reactors\"].append(post['reactors'])\n",
    "        c+=1\n",
    "        print(c,end=',')\n",
    "        if c == 50:\n",
    "            break\n",
    "    print('')\n",
    "    \n",
    "       \n",
    "        \n",
    "    dicts.append(d)\n",
    "\n"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "error",
     "ename": "LoginRequired",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLoginRequired\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-30-c87edee23065>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m             'post_url':[],'reactors':[]}\n\u001B[1;32m      6\u001B[0m     \u001B[0mc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mpost\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mget_posts\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgroup\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0md\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'post_id'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpost\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'post_id'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/facebook_scraper/facebook_scraper.py\u001B[0m in \u001B[0;36m_generic_get_posts\u001B[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source)\u001B[0m\n\u001B[1;32m    314\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    315\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Starting to iterate pages\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 316\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpage\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcounter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miter_pages_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    317\u001B[0m             \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Extracting posts from page %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    318\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mpost_element\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpage\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/facebook_scraper/page_iterators.py\u001B[0m in \u001B[0;36mgeneric_iter_pages\u001B[0;34m(start_url, page_parser_cls, request_fn, **kwargs)\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Requesting page from: %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnext_url\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 39\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrequest_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext_url\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     40\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mHTTPError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNotFound\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/facebook_scraper/facebook_scraper.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, url, **kwargs)\u001B[0m\n\u001B[1;32m    255\u001B[0m                     \u001B[0;32mraise\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAccountDisabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Your Account Has Been Disabled\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m                 \u001B[0;32melif\u001B[0m \u001B[0mtitle\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"Log in to Facebook | Facebook\"\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstartswith\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murljoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mFB_MOBILE_BASE_URL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"login\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLoginRequired\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"A login (cookies) is required to see this page\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mRequestException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mex\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mLoginRequired\u001B[0m: A login (cookies) is required to see this page"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KWH6yfG6nXJA"
   },
   "source": [
    "for i in range(len(dicts)):\n",
    "    df=pd.DataFrame.from_dict(dicts[i],orient='index').transpose()\n",
    "    df.to_csv(f'{groups[i]}.csv')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}