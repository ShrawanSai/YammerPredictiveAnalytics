{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964f1104-45d6-4401-a564-f6a28e9a5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "879f137d-e5ac-40da-81ec-18450f8c7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "924da4cb-ee96-4617-9af3-78dbf6692119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('3_processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8de30da-02be-4de7-8b1e-e236c095f44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>question_mark_check</th>\n",
       "      <th>hashtag_check</th>\n",
       "      <th>url_check</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>words_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>trend_score</th>\n",
       "      <th>image</th>\n",
       "      <th>image_type</th>\n",
       "      <th>video</th>\n",
       "      <th>engagement_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>23</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>15</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  text  question_mark_check  hashtag_check  url_check  \\\n",
       "0           0     1                    0              0          0   \n",
       "1           1     1                    0              0          1   \n",
       "2           9     1                    0              0          0   \n",
       "3          10     1                    0              0          1   \n",
       "4          14     1                    0              0          0   \n",
       "\n",
       "   lexical_diversity  words_count  sentiment  trend_score  image  image_type  \\\n",
       "0           1.000000           18   1.000000         1.00      0           0   \n",
       "1           0.956522           23   0.400000         1.00      0           0   \n",
       "2           1.000000            9   0.000000        14.35      0           0   \n",
       "3           0.933333           15   0.386667         0.00      0           0   \n",
       "4           0.900000           10   0.000000        25.15      0           0   \n",
       "\n",
       "   video  engagement_score  \n",
       "0      0          0.000187  \n",
       "1      0          0.000030  \n",
       "2      0          0.000365  \n",
       "3      0          0.000039  \n",
       "4      0          0.000197  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2fc6dbfc-849c-47a7-9ad7-57cb61a2be75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'question_mark_check', 'hashtag_check',\n",
       "       'url_check', 'lexical_diversity', 'words_count', 'sentiment',\n",
       "       'trend_score', 'image', 'image_type', 'video', 'engagement_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b7ec4d0-e6f1-4352-a670-01c0f2ec433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:12].values\n",
    "y = df.iloc[:, 12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69c5e8cb-3694-4568-9b37-5f9e5aa61d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfdf08ec-d1f2-4d19-92fa-d8b0432ebad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9168ed54-be66-48e0-a23a-55b360717d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=12)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "932f6453-57ce-4635-9167-aa8e50a3dedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0002146731473654732\n",
      "Mean Squared Error: 1.004848106364566e-07\n",
      "Root Mean Squared Error: 0.00031699339210219604\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afbcaad2-653b-4aa3-af68-7e783d641e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['pypcom'] = [sc,regressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41fcf93f-0df7-4891-a693-5afda8590cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'143322019583033': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)],\n",
       " '546588969267691': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)],\n",
       " 'InsaneTech': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)],\n",
       " 'pypcom': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "091ee9dc-956f-4c2a-a251-ba6c1894a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acc1c6d1-0b1c-4368-9b8b-97e2fc3d1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models.pickle', 'wb') as handle:\n",
    "    pickle.dump(models, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12453a66-bbbf-46ae-a5ac-23a926067b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from textblob import TextBlob\n",
    "from meme_or_not import set_model_for_image_type,get_image_type\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "with open('models.pickle', 'rb') as handle:\n",
    "    rf_models = pickle.load(handle)\n",
    "\n",
    "pytrends = TrendReq(hl='en-US', tz=530, timeout=(10,25), retries=3, backoff_factor=0.2)\n",
    "model = set_model_for_image_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b28bdf4d-c1f7-492d-bc8c-4e1e0448ef1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'143322019583033': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)],\n",
       " '546588969267691': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)],\n",
       " 'InsaneTech': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)],\n",
       " 'pypcom': [StandardScaler(),\n",
       "  RandomForestRegressor(n_estimators=20, random_state=12)]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e250d72-2b78-4614-ad1f-d7b4cd665125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(post,image = False,video = False):\n",
    "\n",
    "    def question_mark_check(post):\n",
    "        #print(row['text'])\n",
    "        if '? ' not in str(post):\n",
    "            val = 0\n",
    "        else:\n",
    "            val = 1\n",
    "        return val\n",
    "\n",
    "    def hashtag_check(post):\n",
    "        #print(row['text'])\n",
    "        if '#' not in str(post):\n",
    "            val = 0\n",
    "        else:\n",
    "            val = str(post).count('#')\n",
    "        return val\n",
    "\n",
    "    def url_check(post):\n",
    "\n",
    "        regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "        url = re.findall(regex,str(post))\n",
    "        if len(url)>0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def words_count(post):\n",
    "        return len(str(post).split())\n",
    "\n",
    "    def lexical_diversity(post):\n",
    "        return len(set(str(post).split())) / len(str(post).split())\n",
    "\n",
    "\n",
    "    def sentiment(post):\n",
    "        testimonial = TextBlob(str(post))\n",
    "        return testimonial.sentiment.polarity\n",
    "\n",
    "    def image_check(image):\n",
    "        if not image:\n",
    "            return 0\n",
    "        else:\n",
    "            x = get_image_type(model,image)\n",
    "            return x\n",
    "  \n",
    "    def trend_status(post):\n",
    "\n",
    "        from rake_nltk import Rake\n",
    "\n",
    "        r = Rake() # Uses stopwords for english from NLTK, and all puntuation characters.\n",
    "\n",
    "        r.extract_keywords_from_text(str(post))\n",
    "\n",
    "        words = r.get_ranked_phrases()\n",
    "\n",
    "        proper_nouns = set()\n",
    "        tb = TextBlob(str(post))\n",
    "        for i in tb.tags:\n",
    "            if i[1] == 'NNP':\n",
    "                proper_nouns.add(str(i[0]))\n",
    "\n",
    "        proper_nouns = sorted(list(proper_nouns),key = len, reverse = True)[:5]\n",
    "\n",
    "\n",
    "\n",
    "        if len(words) == 0:\n",
    "            return 0,[]\n",
    "        kw_list = sorted(list(words),key = len, reverse = True)[:5] + proper_nouns\n",
    "        #print(kw_list)\n",
    "        try:\n",
    "            pytrends.build_payload(kw_list, cat=0, timeframe='today 5-y', geo='IN', gprop='')\n",
    "            interest = pytrends.interest_over_time().tail(20)\n",
    "\n",
    "            interest = interest[interest.columns[0]]\n",
    "        except:\n",
    "            if len(proper_nouns) < 1:\n",
    "                return 0,kw_list\n",
    "            #print(proper_nouns)\n",
    "            pytrends.build_payload(proper_nouns, cat=0, timeframe='today 5-y', geo='IN', gprop='')\n",
    "            interest = pytrends.interest_over_time().tail(20)\n",
    "\n",
    "            try:\n",
    "                interest = interest[interest.columns[0]]\n",
    "            except:\n",
    "                return 0,kw_list\n",
    "\n",
    "        x = interest.mean()\n",
    "        if x == 0:\n",
    "            #print(\"no interest\")\n",
    "            if len(proper_nouns) < 1:\n",
    "                return 0,kw_list\n",
    "            #print(proper_nouns)\n",
    "            pytrends.build_payload(proper_nouns, cat=0, timeframe='today 5-y', geo='IN', gprop='')\n",
    "            interest = pytrends.interest_over_time().tail(20)\n",
    "\n",
    "            try:\n",
    "                interest = interest[interest.columns[0]]\n",
    "            except:\n",
    "                #print('fail')\n",
    "                return 0,kw_list\n",
    "            return interest.mean(),kw_list\n",
    "        return x,kw_list\n",
    "\n",
    "\n",
    "    def text_boolean(post):\n",
    "        #print(row[''])\n",
    "        if len(str(post)) > 0:\n",
    "            val = 1\n",
    "        else:\n",
    "            val = 0\n",
    "        return val\n",
    "    \n",
    "    post = input()\n",
    "    trend_s, keywords = trend_status(post)\n",
    "    if not image:\n",
    "        image_status = 0\n",
    "        image_type = 0\n",
    "    else:\n",
    "        image_status = 1\n",
    "        image_type = image_check(image)\n",
    "    if not video:\n",
    "        video_status = 0\n",
    "    else:\n",
    "        video_status = 1\n",
    "    parameters = [1,question_mark_check(post),hashtag_check(post),url_check(post),lexical_diversity(post),\n",
    "                 words_count(post), sentiment(post),trend_s,image_status,image_type,video_status]\n",
    "    #parameters.append(int(input(\"image?\")))\n",
    "    #parameters.append(int(input(\"image type?\")))\n",
    "    #parameters.append(int(input(\"video?\")))\n",
    "    #parameters.append(input(\"engagement_score ?\"))\n",
    "    \n",
    "    return parameters,keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c84e3f7c-02df-497b-916f-dae428fba554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(post,group_id,image = False,video = False):\n",
    "    \n",
    "    x,kw = get_metrics(post,image,video)\n",
    "    second = x.copy()\n",
    "    second[1] = 1 #If no question add question\n",
    "\n",
    "    third = x.copy()\n",
    "    third[2] += 1 #Increase hashtag by 1\n",
    "\n",
    "    fourth = x.copy()\n",
    "    fourth[2] += 3#Increase hashtag by 3\n",
    "\n",
    "    fifth = x.copy()\n",
    "    fifth[3] = 1#If no url, add\n",
    "\n",
    "    sixth = x.copy()\n",
    "    sixth[5] += int(0.25*sixth[5]) #Increase word count by 25%\n",
    "\n",
    "    seventh = x.copy()\n",
    "    seventh[5] += int(0.5*seventh[5])#Increase word count by 50%\n",
    "\n",
    "\n",
    "    eight = x.copy()\n",
    "    eight[5] += int(0.75*eight[5])#Increase word count by 75% \n",
    "\n",
    "    ninth = x.copy()\n",
    "    ninth[5] -= int(0.25*ninth[5])#Decrease word count by 25%\n",
    "\n",
    "    tenth = x.copy()\n",
    "    tenth[5] -= int(0.5*tenth[5])#Decrease word count by 50%\n",
    "\n",
    "    eleventh = x.copy()\n",
    "    eleventh[5] -= int(0.75*eleventh[5])#Decrease word count by 75%\n",
    "\n",
    "    twelfth = x.copy()\n",
    "    twelfth[5] = 5#Word count as 5\n",
    "\n",
    "    thirteen = x.copy()\n",
    "    thirteen[6] += 0.1*thirteen[6]#Increase sentiment by 10%\n",
    "\n",
    "    fourteen = x.copy()\n",
    "    fourteen[6] += 0.25*fourteen[6]#Increase sentiment by 25%\n",
    "\n",
    "    fifteen = x.copy()\n",
    "    fifteen[7] += 0.1*fifteen[7]#Increase trend score by 10%\n",
    "\n",
    "    sixteen = x.copy()\n",
    "    sixteen[7] += 0.25*sixteen[7]#Increase trend score by 25%\n",
    "\n",
    "    seventeen = x.copy()\n",
    "    seventeen[8],seventeen[9] = 1,1#Add image as meme\n",
    "\n",
    "    eighteen = x.copy()\n",
    "    eighteen[8],eighteen[9] = 1,-1#Add image as infogrphic\n",
    "\n",
    "    nineteen = x.copy()\n",
    "    nineteen[8],nineteen[9],nineteen[10] = 0,0,1#Add video\n",
    "\n",
    "\n",
    "    to_predict = [x,\n",
    "                 second,third,fourth,fifth,sixth,seventh,eight,ninth,tenth,eleventh,twelfth,thirteen,\n",
    "                 fourteen,fifteen,sixteen,seventeen,eighteen,nineteen]\n",
    "    \n",
    "    sc = rf_models[group_id][0]\n",
    "    regressor = rf_models[group_id][1] \n",
    "    input_ex = sc.transform(to_predict)\n",
    "    y_pred = regressor.predict(input_ex)\n",
    "    \n",
    "    best_suggestion = np.argmax(y_pred) + 2\n",
    "    \n",
    "    return define_best_suggestion(best_suggestion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fefb5ee1-ac03-4bad-8091-8a7097f4e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_best_suggestion(p):\n",
    "    \n",
    "    if p == 2:\n",
    "        return 'Adding a question to your post increases your posts engagement score'\n",
    "    elif p == 3:\n",
    "        return 'Try adding a hashtag. It seems like your post might do better'\n",
    "    elif p == 3:\n",
    "        return 'Try adding a hashtag. It seems like your post might do better'\n",
    "    elif p == 4:\n",
    "        return 'Adding 3 hashtags more seems like it will make a significant difference. Your post might do better'\n",
    "    elif p == 5:\n",
    "        return 'Can your post include a link to an article/video? Try adding this for better engagement'\n",
    "    elif p == 6:\n",
    "        return 'Number of words make a difference. A 25% increase in number of words in your post seems promising'\n",
    "    elif p == 7:\n",
    "        return 'Number of words make a difference. A 50% increase in number of words in your post seems promising'\n",
    "    elif p == 8:\n",
    "        return 'Number of words make a difference and it seems your post is too small. A 75% increase in number of words in your post seems promising'\n",
    "    elif p == 9:\n",
    "        return 'Number of words make a difference. A 25% decrease in number of words in your post seems promising'\n",
    "    elif p == 10:\n",
    "        return 'Your post is a bit too lengthy. If you try reducing the length of the post to about 50% its length, it may do much better'\n",
    "    elif p == 11:\n",
    "        return 'Your post is a bit too lengthy. If you try reducing the length of the post to about 25% its length, it may do much better'\n",
    "    elif p == 12:\n",
    "        return 'Try keeping the number of words limited to around 5. It look like for this post something short seems perfect'\n",
    "    elif p == 13:\n",
    "        return 'If the positive sentiment conveyed in your tweet is increased by 10%, it will do better'\n",
    "    elif p == 14:\n",
    "        return 'If the positive sentiment conveyed in your tweet is increased by 25%, it will do better'\n",
    "    elif p == 15:\n",
    "        return 'Including topics in trend in your tweet is always a good thing. Try including a few buzzwords. A 10% increase in trend score will help'\n",
    "    elif p == 16:\n",
    "        return 'Including topics in trend in your tweet is always a good thing. Try including a few buzzwords. A 25% increase in trend score will help'\n",
    "    elif p == 17:\n",
    "        return 'Including images in your post is always a good idea. Adding a meme or a image conveying humour might help'\n",
    "    elif p == 18:\n",
    "        return 'Including images in your post is always a good idea. Adding an image of a graph or some sort of infographic seems perfect'\n",
    "    elif p == 19:\n",
    "        return 'Including videos in your post is helpful at times. Posting a video seems like it helps engagement score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2d1a08a-b059-4d4f-92a3-d71173ffdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "second = x.copy()\n",
    "second[1] = 1 #If no question add question\n",
    "\n",
    "third = x.copy()\n",
    "third[2] += 1 #Increase hashtag by 1\n",
    "\n",
    "fourth = x.copy()\n",
    "fourth[2] += 3#Increase hashtag by 3\n",
    "\n",
    "fifth = x.copy()\n",
    "fifth[3] = 1#If no url, add\n",
    "\n",
    "sixth = x.copy()\n",
    "sixth[5] += int(0.25*sixth[5]) #Increase word count by 25%\n",
    "\n",
    "seventh = x.copy()\n",
    "seventh[5] += int(0.5*seventh[5])#Increase word count by 50%\n",
    "\n",
    "\n",
    "eight = x.copy()\n",
    "eight[5] += int(0.75*eight[5])#Increase word count by 75% \n",
    "\n",
    "ninth = x.copy()\n",
    "ninth[5] -= int(0.25*ninth[5])#Decrease word count by 25%\n",
    "\n",
    "tenth = x.copy()\n",
    "tenth[5] -= int(0.5*tenth[5])#Decrease word count by 50%\n",
    "\n",
    "eleventh = x.copy()\n",
    "eleventh[5] -= int(0.75*eleventh[5])#Decrease word count by 75%\n",
    "\n",
    "twelfth = x.copy()\n",
    "twelfth[5] = 5#Word count as 5\n",
    "\n",
    "thirteen = x.copy()\n",
    "thirteen[6] += 0.1*thirteen[6]#Increase sentiment by 10%\n",
    "\n",
    "fourteen = x.copy()\n",
    "fourteen[6] += 0.25*fourteen[6]#Increase sentiment by 25%\n",
    "\n",
    "fifteen = x.copy()\n",
    "fifteen[7] += 0.1*fifteen[7]#Increase trend score by 10%\n",
    "\n",
    "sixteen = x.copy()\n",
    "sixteen[7] += 0.25*sixteen[7]#Increase trend score by 25%\n",
    "\n",
    "seventeen = x.copy()\n",
    "seventeen[8],seventeen[9] = 1,1#Add image as meme\n",
    "\n",
    "eighteen = x.copy()\n",
    "eighteen[8],eighteen[9] = 1,-1#Add image as infogrphic\n",
    "\n",
    "nineteen = x.copy()\n",
    "nineteen[8],nineteen[9],nineteen[10] = 0,0,1#Add video\n",
    "\n",
    "\n",
    "to_predict = [x,\n",
    "             second,third,fourth,fifth,sixth,seventh,eight,ninth,tenth,eleventh,twelfth,thirteen,\n",
    "             fourteen,fifteen,sixteen,seventeen,eighteen,nineteen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65cf5282-400e-4a3e-995e-da927cd443b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 4, 1, 0.8169014084507042, 71, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 1, 4, 1, 0.8169014084507042, 71, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 5, 1, 0.8169014084507042, 71, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 7, 1, 0.8169014084507042, 71, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 88, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 106, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 124, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 54, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 36, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 18, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 5, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 0.8800000000000001, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 1.0, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 0.8, 63.03, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 0.8, 71.625, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 0.8, 57.3, 1, 1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 0.8, 57.3, 1, -1, 0],\n",
       " [1, 0, 4, 1, 0.8169014084507042, 71, 0.8, 57.3, 0, 0, 1]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec20483f-71b9-44d8-bb54-d42569ed07af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5228661c-a718-4e5f-b9e2-97b99de38975",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ex = sc.transform(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02404bea-1110-432a-a713-2cd303e6c688",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(input_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a18030f0-977a-44e8-8e86-1bfc289b052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000214  , 0.00021598, 0.000214  , 0.000214  , 0.000214  ,\n",
       "       0.000214  , 0.000214  , 0.000214  , 0.000214  , 0.00021598,\n",
       "       0.00024211, 0.00015705, 0.000214  , 0.000214  , 0.000214  ,\n",
       "       0.000214  , 0.000214  , 0.000214  , 0.00021647])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc8beaf2-b745-4152-942a-d693e7de25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_suggestion = np.argmax(y_pred) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a381d75e-4474-4c87-9eae-7b7c9bba0a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85808b-1ff2-452e-a08e-88ba6660ba7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
